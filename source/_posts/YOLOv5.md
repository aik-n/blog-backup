---
title: YOLOv5
date: 2021.12.1
author: Aik
img: /source/images/xxx.jpg
top: true
hide: false
cover: true
coverImg: /images/1.jpg
password: 
toc: true
mathjax: true
summary: YOLO做目标检测
categories: YOLO
tags:
  - YOLO
---



# YOLOv5算法原理和网络结构

YOLO的思路起源于将基本的CNN思路从分类任务扩展到检测中。传统目标检测算法，主要分为三步：选择区域框、提取特 征、归分类别，这就存在有两个问题；一是区域选择的方法效果 不佳、且时间成本很高；二是提取的区域框鲁棒性很差。随后 出现的R-CNN系列算法，需要提前生成大量的Region Proposal （候选区），在候选区的基础上提取特征，花费很多时间。YOLOv5 作为YOLO系列最新的版本，由于其独特的网络结构和算法，在检测速度和精度上都能取得很不错的效果。

## YOLOv5

YOLOv5算法共有4种目标检测网络，分别是YOLOv5s、YOLOv5m、YOLOv5l、YOLOv5x四个模型。这几种网络结构原理上基本一致，接下来以YOLOv5x为例介绍YOLOv5网络结构。

YOLOv5的网络结构如图1所示。该结构分为输入端、Backbone(主干网络)、Neck、Prediction(输出端)四个部分。

各部分的主要功能如下：

输入端：Mosaic数据增强、自适应锚框计算、自适应图片缩放。

Backbone：Focus结构，CSP结构。

Neck：FPN+PAN结构。

Prediction：GIOU_Loss。

![img](file:///C:/Users/xwy/AppData/Local/Temp/msohtmlclip1/01/clip_image002.png)

**图1 YOLOv5x**的网络结构图

### 输入端

(1)   Mosaic数据增强

Mosaic数据增强提出的作者来自Yolov5团队的成员。通过对多个图像进行随机缩放、随机裁剪、随机排布的方式进行拼接，这种方法对于小目标的检测效果还是很好的。

这种方法有以下两个优点：

丰富了数据集：随机使用几张图片，随机缩放，再随机分布进行拼接，大大丰富了检测数据集，特别是随机缩放增加了很多小目标，让网络的鲁棒性更好。

减少GPU使用：Mosaic增强训练时，可以直接计算这从数据集中读取图片的数据，使得Mini-batch大小并不需要很大，一个GPU就可以达到比较好的效果。

![img](file:///C:/Users/xwy/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg)

**图2** **数据增强**

(2)   自适应锚框计算

在YOLO模型中，针对不同的数据集，都会有初始设定长宽的锚框。

在网络训练中，网络在初始锚框的基础上输出预测框，进而和真实框GroundTruth进行对比，计算两者差距，再反向更新，迭代网络参数。

可见初始锚框是非常重要的一部分，在YOLOv3、YOLOv4中，训练不同的数据集时，计算初始锚框的值是通过单独的程序运行的。但是YOLOv5中将此功能嵌入到代码中，每次训练时，自适应的计算不同训练集中的最佳锚框值。

(3)   自适应图片缩放

在常用的目标检测算法中，不同的图片长宽都不相同，因此常用的方式是将原始图片统一缩放到一个标准尺寸，全部处理后再送入检测网络中。将长宽800*600的图像进行缩放，使用黑色背景来填充，填充后会出现大区域的黑边。在项目实际使用时，图片的长宽比几乎都不相同，因此缩放填充后，黑边大小都不同，如果填充的比较多，则存在信息冗余，影响网络推理速度[3]。

在项目实际使用时，很多图片的长宽比不同，因此缩放填充后，两端的黑边大小都不同，而如果填充的比较多，则存在信息冗余，影响推理速度。因此在YOLOv5的代码中datasets.py的letterbox函数中进行了一定修改，对原始图像自适应的添加最少的黑边，这样处理后，使用模型推理时，计算量也会得到减少，从而使得网络的目标检测速度会得到提高，这也是 YOLOv5算法处理速度能够变快的一个原因。而这种简单的改进可以提升37%的推理速度。

该算法分为以下三步：

第一步：计算缩放比例

原始缩放尺寸是416*416，都除以原始图像的尺寸后，可以得到0.52，和0.69两个缩放系数，选择小的缩放系数。

第二步：计算缩放后的尺寸

原始图片的长宽都乘以最小的缩放系数0.52，宽变成了416，而高变成了312。

第三步：计算黑边填充数值

将416-312=104，得到原本需要填充的高度。再采用numpy中np.mod取余数的方式，得到8个像素，再除以2，即得到图片高度两端需要填充的数值。

### Backbone

(1)   Focus结构

YOLOv5x 网络的 Focus 结构中，通过最后卷积操作时，卷积核的数量是32个，以网络输入图像 608*608 像素大小为例，经过 Focus 结构，特征图的大小变成 304*304*80，在第2个卷积操作时，YOLOv5x 网络使用了160 个卷积核，因此得到的特征图是 152*152*160，后面 3 个卷积和下采样操作也是同样的原理，最后得到的特征图向量分别为 19*19*1 280、38*38*1 280、76*76*1 280。

(2)   CSP结构

YOLOv5中有两种结构的CSP，CSP1_X结构在Backbone主干网络中，另一种CSP2_X结构在Neck中。对于Backbone的主干网络结构，CSP 模块中的卷积核大小都是3*3，步进值为2，假如输入的图像尺寸是608*608，那么它的特征图变化的规律是：608*608 -> 304*304 -> 152*152 -> 76*76 -> 38*38 -> 19*19，最终得到了一个19*19大小的特征图。

使用CSP模块的优点：

一是增强网络的学习能力，使得训练出的模型，既能保持轻量化，又能有较高的准确性。

二是降低计算瓶颈。

三是降低内存成本。

### Neck

Yolov5现在的Neck和Yolov4中一样，都采用FPN+PAN的结构，但在Yolov5刚出来时，只使用了FPN结构，后面才增加了PAN结构，此外网络中其他部分也进行了调整。FPN是自顶向下的，通过上采样操作，将高层的特征信息和低层特征进行融合，计算出预测的特征图[3]。YOLOv5网络结构中在FPN层后面，还添加了一个特征金字塔，自下向上，其中有两个PAN结构，通过下采样操作，将低层的特征信息和高层特征进行融合，输出预测的特征图。

###  Prediction

Prediction由非极大值抑制（NMS）和Bounding box损失 函数两大部分组成。在Bounding box中，GIOU_Loss函数作为损失函数，通过NMS函数可以在预测结果处理阶段解决重合目标边框或进行筛选。

## YOLOv5网络结构分析

YOLOv5的4种网络结构YOLOv5s、YOLOv5m、YOLOv5l和 YOLOv5x 内 容 基 本 一 样 ，只 在 深度和宽度上不同，通 过 depth_multiple 和 width_multiple 两个参数来进行控制，其中前 者控制网络深度，后者控制网络宽度[4]。现在分析4种网络结构的差异。

#  实验与结果

##  实验环境与超参数设置

实验使用带有英特尔内核的笔记本PC 上进行的， 配置6 GB 的RAM, NVIDIA GeForce GTX 1060图形显卡，windows10 操作系统，CPU 是 Intel(R) Core(TM) i7-6700HQ CPU @ 2.6GHz，4 核心，支持 8 线程，主频 2.6 GHz。cuda 版本是 11．0，集成开发环境是Pycharm，编程语言是Pyhon3.8。 

YOLOv5x 模型训练参数的设置，批处理大小 (batchSize) 设为 8，迭代次数( epochs) 设为 500 次，输入图片尺寸为1280*1280，学习率设置为 0.01。

##  数据准备

本文的数据来源于农科院研究所，使用无人机对试验田中不同生长状态的玉米进行拍摄的照片。数据图片共有111张，拍摄高度从33.8到34.27不等，每张图片像素大小为8192*5460。

将得到的采集数据进行整理，由于原无人机航拍图像素值较大，而玉米花的像素值较小，直接将图片进行标注与训练，得到的模型效果不理想。所以需要进行一定的预处理操作，这里把每张图片按照4排4列的方式，均匀切分为16张图片，得到的每张图片像素值为2048*1365，总共1776张小图。使用标记软件labelimg 对这些图片中的已开花朵进行标注。总共标记开花图片数量188张。数据标注示例如图3所示。

 ![img](file:///C:/Users/xwy/AppData/Local/Temp/msohtmlclip1/01/clip_image006.png)

**图3** **数据标注**

##  实验结果分析

如通过500次迭代，可以看出模型最后逐渐收敛，趋于稳定。

![img](file:///C:/Users/xwy/AppData/Local/Temp/msohtmlclip1/01/clip_image008.png)

**图4**

![img](file:///C:/Users/xwy/AppData/Local/Temp/msohtmlclip1/01/clip_image009.png)

**图5**

将训练好的模型进行预测，并将裁剪的图片拼接起来，最后的效果图如下所示。预测准确率达92.24%，总体效果还是不错的。Yolov5算法相较于Yolov4，具有更高的实时性和准确性。更换输入图片尺寸后，结果更明显，是否进一步改进其他系数还需要其他试验深入分析。

![img](file:///C:/Users/xwy/AppData/Local/Temp/msohtmlclip1/01/clip_image011.jpg)

**图6** **检测结果**
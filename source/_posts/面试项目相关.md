# 校园优享

**技术选型：**Redis+Spring Boot+MySQL+Mybatis+RabbitMQ+Nginx+Docker

**项目描述：**为高校学生提供的一个校园周边商铺的点评项目，实现了短信登陆、店铺查询、优惠券秒杀、发表点评、关注推送的完整业务流程。

**个人职责：**

- 通过**ThreadLocal**保存当 前用户信息，并封装工具类简化操作，极大程度上简化了获取用户信息的操作。
- 使用**两层拦截器**实现用户访问时的登录校验、访问权限和登录有效期的刷新。
- 采用主动更新+超时剔除的方式保证了数据库和**缓存**数据间的高**一致性**。
- 使用Redis对高频访问的数据进行**缓存**，降低了数据库的负载压力，解决了**缓存穿透、缓存雪崩和缓存击穿**问题。
- 使用Redis+Lua脚本实现对用户秒杀资格的预检，同时用乐观锁解决秒杀产生的**超卖**问题。
- 使用**Redis分布式锁**解决了在集群模式下**一人一单**的线程安全问题。
- 基于RabbitMQ消息队列，实现**异步秒杀下单**的功能。
- 使用Redis的**ZSet**数据结构实现了点赞排行榜功能，使用**Set**集合实现关注、共同关注、推送等功能。



## 登录

### 为什么使用Redis替代Session做登录功能？

**首先**，Session的数据存储在服务器端，数据量大的时候会占用JVM的内存空间，影响性能。而Redis则作为一个独立的服务，可以专门用来做这一部分的数据存储，而且由于是基于内存的，所以读写效率非常高。

**其次**，在分布式的系统下，每一个服务器的Session数据是相互隔离的，因此，用户在不同服务器上访问不同服务的时候会因为Session的不一致导致需要反复进行登录验证。而多个服务可以访问同一个Redis来获取用户的登录信息，实现了数据的共享。此外Redis集群内部的数据一致性机制也非常完善（主从复制）

### 验证码

采用String类型进行数据的存储，将标识符前缀（如login:code:）+手机号作为key保证了key的唯一性，将验证码作为value，设置TTL存入Redis中，登录时通过比对该条数据来判断是否登陆成功。

### 用户Token

用户在访问部分页面时需要获取访问权限，若用户已进行登录，则在用户登录后访问服务时会在请求头中携带**Authorization**授权码。因此，在用户登陆成功的时候会从后端返回一个Token给前端，并且在Redis中以Token为唯一标识**存储**一些**用户的基本信息**，如用户id，昵称等，因此这块采用**hash结构**进行存储。

hash的key采用标识符前缀（如login:user:）+UUID来确保**唯一性**。

每次在用户请求服务的时候首先经过拦截器，通过判断携带的token信息是否存在于Redis中，不存在则拦截返回401，存在则将Redis存放的用户基础信息存入**ThreadLocal**中，方便后续业务查询中获取当前用户信息。

### 登录有效期刷新

由于用户信息在Redis中是有有效期的，因此采用**两层拦截**的方式，只要用户处于登录状态访问了服务，无论是否需要权限，都先去**刷新**Redis中用户信息的TTL，防止用户在浏览一些商铺信息时过久导致的**登录失效**问题。



## 缓存

### 为什么使用缓存？

在高并发的场景下，用户对于一些热点数据，如商品信息等访问请求量很大，如果每一次请求都访问数据库，那么对数据库的压力是非常大的，因此考虑使用缓存。

### 缓存一致性策略

采用主动更新+超时剔除的策略，像给热点店铺信息增加缓存的时候，数据库信息进行更改的同时，编写业务直接修改Redis中的缓存数据，并且通过添加过期时间来减少热点key的内存占用。

### 当数据库中的数据发生变化的时候，是删除缓存还是更新缓存？

删除缓存。因为如果采用更新缓存的方案，那么一段时间内数据库中的数据发生了多次变化，那么在这期间就得不断地更新缓存，但这些更新操作其实都是无效的，因为没有人来访问数据。因此应该直接删除缓存，当有用户查询数据的时候再将数据写入到缓存中。

### 如何保证缓存和数据库的操作同时成功？

单体项目使用事务注解@Transaction，分布式项目使用分布式事务框架。

### 先更新数据库还是先删缓存？

如果**线程1**把缓存删除掉，此时有**线程2**访问该条数据，发现没有，那么就去数据库里面查找，但此时数据库的数据还没更新，**线程2**又把数据库里的脏数据写入到了缓存中。最终缓存中保留的是脏数据。

如果**线程1**更新数据库，在更新数据库前有**线程2**查询到了旧的数据，但是在写入缓存的时候**阻塞**了，此时**线程1**换成更新，并且完成了缓存删除，这时候**线程2**继续执行了，将脏数据又写入了缓存。

因此需要采用**延迟双删**的方法，先删除一次缓存，然后更新数据库，之后延迟再一次删除缓存，**保证最终一致性**。

### 什么是缓存穿透？

客户端请求的数据在缓存中和数据库中都不存在，每一次的请求请求都会打到数据库上，如果并发量特别高会给数据库带来巨大的压力。

### 项目中如何解决缓存穿透问题？

本项目采用缓存空对象的方式解决了缓存穿透问题。当一个前端请求在缓存中没有查找到，并且数据库中也没查找到，那么就在Redis中缓存一个空值对象，这样再有请求打到缓存中，如果发现是空对象，那么直接就返回结果，不再打到数据库。

当然还是要设置TTL，不然如果后期这个请求的数据在数据库中确实存在了，那么会一直查询不到。

同时也要增强数据id的复杂度，避免被猜测id规律，做好数据的基础格式校验，加强用户权限校验，做好热点参数的限流。

### 什么是缓存雪崩？

**缓存雪崩**是指在同一时段大量的缓存key**同时失效**或者Redis服务**宕机**，导致大量请求到达数据库，带来巨大压力。

### 怎么解决缓存雪崩的？

给不同的key设置随机的TTL来缓解这个问题。利用Redis集群提高服务的高可用性。

### 什么是缓存击穿？

**缓存击穿**问题也叫**热点Key**问题，就是一个被高并发访问并且**缓存重建业务较复杂**的key突然**失效了**，无数的请求访问会在瞬间给**数据库**带来巨大的冲击。**（注意：是key已经失效而带来的问题，没失效就说明不是缓存击穿问题）**，比如说一个热门商铺信息，同时有很多人访问。一旦缓存过期，那么很多人的请求就直接打到数据库上，数据库就很有可能出现宕机的情况。

### 如何解决缓存击穿问题？

常见的有两种方式

第一种方式采用互斥锁，当获取热点Key失败时，**先获取互斥锁**（SETNX）,只有获取到互斥锁才进行缓存重建，其他线程会进行**阻塞**并不断重试获取热点key，这种方式会使得系统性能降低，因为很多线程都处于阻塞的情况，并且存在**死锁**的风险。

第二种方式采用**逻辑过期**的方式，在缓存中保存数据的同时，同时写入一个逻辑过期的时间戳，并且**不设置TTL**，因此不会由于key失效而产生缓存击穿的问题。在发起请求的时候先通过当前时间判断该数据是否真的过期了，如果逻辑过期那么就开一个**异步线程来重建缓存**，当前线程**直接返回旧的数据**。这种实现方式的并发性能比较好，但是由于是异步更新缓存，所以在这一小段时间内用户读到的都是脏数据。

### 说说CAP定理？

CAP是指在一个分布式系统中，一致性（C）、可用性（A）、分区容忍性（P）只能同时存在两个。

常见的就是CP和AP，即在保证系统正常运作的情况下，要么只能保证**一致性**，即所有节点的数据在同一时刻应当保证相同，要么只能保证**可用性**，即。

类似解决缓存击穿问题中，互斥锁的方案就是CP的，保证了获取到的数据始终是一致的，不存在脏读的问题。像逻辑过期的方案就是AP的，只保证请求一定有数据返回，但是不保证返回的是不是最新的数据。

## 秒杀

### 如何确保高并发的情况下秒杀订单ID的唯一性

用户在抢购优惠券的时候，每个订单需要确保对应一个**唯一**ID，并且保证这个ID的生成具有**高可用**。

本项目实现了一个全局唯一ID，共64位，其中第一位为0，代表正数，后面31位代表一个以秒为单位的时间戳，最后32位是通过redis的increment函数来实现的自增ID，代表每秒可以生成$$2^{32}$$个ID。

存放的key采用业务名：日期：的形式存放，方便统计每日的订单数量和**防止超出**单个key自增长的**上限**（Redis 的整数值是 64 位带符号整数，因此自增键的上限是 2^63 - 1）

### 超卖问题具体如何解决的？

秒杀伴随着高并发量，在判断库存和实际修改库存之间，容易出现线程穿插执行的情况，导致最终库存扣减过多的问题。

一般有两种解决方案，悲观锁和乐观锁，但悲观锁的执行效率太低，不适合高并发的业务场景，因此采用乐观锁的方式。一开始用的版本号法，就是不仅保存库存量，同时还保存一个版本号，修改库存的时候判断一下版本号是否和查询时获取到的**版本号相同**，如果**不相同**就**不**进行库存的**扣减**。但这种方式会导致很多人下单时虽然有库存但由于版本号被修改了导致此次的下单操作失败。实际上只要库存还有就可以进行下单，因此后来采用**CAS**法进行简化，直接在库存扣减的同时判断库存是否>0即可。

### 如何解决一人一单的问题？

从理论上来说，只需要在代码中判断完库存充足以后，然后在判断一下用户是否下过单即可，如果下过单，则直接返回异常信息。但是在使用JMeter测试时，发现依然可以一个用户下多个订单的情况。此时就出现了线程安全问题。

解决这个问题只能通过悲观锁的方式，确保检验下单资格和创建订单的原子性。并且通过id.toString().intern()返回与当前id相同的String对象来作为synchronized的标识，这样每个用户都会去获取属于自己的锁，使得不同用户间互不影响并发操作。

这里需要通过代理对象来调用带有事务的方法，否则会使得事务不生效，因此可以通过延迟注入自己的方式来获取到当前类的代理对象。

### 集群模式下的一人一单如何解决？

由于是在不同JVM中，锁监视器只存在于每个JVM内部，所以需要通过分布式锁的方式，而利用Redis中的**SETNX**就可以实现一个简单的分布式锁，每个用户在不同进程下的请求只有一个能获取到锁，通过设置TTL来避免可能出现的**死锁**问题。

但是这种方式可能带来一些问题，比如线程1在执行业务期间阻塞时间过久导致TTL失效了，此时就会有线程2来执行业务，从而出现**线程安全**问题。

为了避免**误删别的线程锁**的问题，在存入锁的时候用**UUID+线程id**的方式来作为**value**，（因为单用线程id会有可能两个进程的线程id相同）当作一个**标识符**，在删除前取出判断当前获取到的和最开始存进去的是否相同，不同则代表是别的线程的锁，不进行删除，并且**抛出异常**，让之前提交的**事务**进行**回滚**，避免又出现一人多单的情况。由于判断锁里记录的线程是否相同和删除锁是两个操作，因此通过Lua脚本的方式保证原子性。

> 但手动抛异常让事务回滚的方式如果出现业务本身执行耗时就很长的情况，或者一段时间内存在异常导致业务执行速度缓慢，这样的话就会导致永远没有业务可以执行完，因为事务全被回滚了。

> 但如果看门狗一直续TTL，也会导致必须等待当前线程阻塞结束才会执行业务，假如当前线程由于某种原因导致一直阻塞，那么也无法执行完这个业务。

### 可重入锁如何实现的？

利用hash结构实现分布式锁，额外存入一个count值，获取相同锁的时候count+1，释放锁的时候count-1，只有当count为0时才将锁删除。解决业务中需要多次获取同一把锁的问题。

### Redis集群下的分布式锁怎么实现？

为了提高redis的可靠性，通常采用**主从**集群的方式对redis做扩展。由于主从复制存在一定的延迟性，因此可能会出现在主机获取锁成功后，由于主机宕机，导致从机上还没有同步获取锁，由于哨兵机制，会选取从机来作为新的一个主机，从而导致锁丢失的问题。这样如果**又来一个线程**获取锁，那么**又能**获取这把锁，导致出现了线程安全问题。利用Redisson的联锁，这样如果有一台出现了这种极端情况，那么就会其他线程获取锁失败。

### 如何使用MQ完成的异步秒杀，讲讲秒杀业务的整体流程？

**首先**，在秒杀活动开启前，先做数据的预热，将秒杀的优惠券库存信息缓存到redis中，以更好的应对高并发的情况。为了防止用户在活动开始前通过非常规手段来访问接口，后端在对于秒杀活动的开始和结束时间也要做好相应的判断（不能完全相信前端）。**其次**，为当前用户生成一个全局唯一ID，接着去判断用户是否存在购买的资格，也就是用一个redis的set集合来存入用户id，通过判断用户是否存在于set集合中来判断是否有购买资格，接着判断库存是否充足，都满足之后，再将redis中库存数量进行扣减，然后将用户id保存到set中。**接着**发送消息给MQ。**最后**，由MQ消费者来执行落库操作，完成数据库订单的生成以及库存的扣减操作。

### 如何应对生产者发送消息时失败的问题？

首先，可以在RabbitMQ中配置生产者的重连机制，在连接MQ的时候产生网络波动的情况下进行有限次数的重连，避免由于网络波动产生的发送失败。其次，如果是由于其他的原因导致的失败，MQ还支持生产者确认机制，只要开启了生产者确认机制，当生产者发送了消息到MQ时，MQ会给一个ACK回执，发送失败时会返回NACK回执，根据返回的消息，如果是NACK就可以进行重发，如果多次发送失败，可以直接进行日志记录，通知人工处理。通过以上手段就可以基本保证生产者消息的可靠性，但是通过这种方式会增加系统的负担，因此大多数情况下并不需要开启此机制，除非对于消息可靠性有着较高的要求。

### 如何应对消费者消费消息时失败的问题？

RabbitMQ提供了**消费者确认机制**，当消费者处理消息后应当发送一个回执给MQ，告知消息的处理结果，（**ack、nack、reject**）。可以开启ACK的auto模式，**SpringAMQP**通过AOP对消息处理做了动态增强，当业务正常执行时自动返回ACK，当出现**异常**时，如果时业务异常就返回一个**nack**通知MQ**再次投递**消息进行处理，如果是**消息类型转换异常**，那么就是代码层面的问题，直接返回**reject**，将该条有问题的数据从MQ中直接**删除**。

但是如果处于业务异常的情况下，反复的投递消息，返回nack，这会给MQ带来不必要的性能压力。因此，可以通过开启MQ的**消费者重试机制**，在出现异常的时候先直接本地进行**重试**，超过一定次数后，直接将该消息投递到一个**error队列**中，专门交给**人工**进行处理。

### 如何保证消费时的业务幂等性问题？

幂等性是一个数学概念，意思就是同一个业务，执行一次和执行多次应该结果上是一样的，比如查询和删除的操作天生就是幂等的，而像扣减库存和退款之类的操作，就不是幂等的。

如果由于某些原因导致生产者方发送了多条重复消息，那么就有必要去保证这个幂等性，不然会导致一人多单等问题的发生。

本项目通过唯一消息ID的方式解决了这个问题，每一条消息发送时都携带一个唯一ID，在消费者接收到消息的时候先判断该ID是否存在于Redis的某个字段中，并且通过Lua脚本来实现判断和存入ID两部操作的一致性，根据返回的结果来做落库的操作。

## 点赞、关注、推送

### 点赞排行榜是怎么做的？

一人一赞可以用SET数据类型完成，但由于需要做排序，而SET是无序的，所以这里采用ZSET的结构，将用户点赞时的LocalTime作为SCORE进行存储。这样，在获取用户点赞排行的时候直接通过range来获取一个指定范围内的有序排列。

但这里出现过一个问题，就是在用sql语句返回查询的用户信息list的时候出现了**顺序错乱**的情况，因为是用**in**做的查询，所以返回的是按照id在用户表里的排序的结果。所以这里用了field函数来确保返回的顺序和传入的idList顺序是一致的。

但如果不直接返回list，而是遍历的方式一个一个返回，那确实不会出现这种问题，但是这种的执行效率就很差。

### 关注怎么做的，共同关注怎么做的？

关注就是用一张表来存放被关注的用户id以及关注的用户id。共同关注用Set结构的**交集**运算，先获取到两个用户的各自关注的用户id列表，再取交集。

### 推送怎么实现的，存在哪些难点问题吗？

推送也叫feed流，主要有两种大的方向， 一种是**timeline**，不做内容筛选，直接将信息排序展示，比如微信朋友圈这种；还有一种是**智能排序**，用一些智能算法去屏蔽违规的以及用户不敢兴趣的内容，只推送可能感兴趣的，如抖音短视频。由于本项目是实现的关注及推送，所以选用第一种。

这种又分为三种实现方案，拉，推，推拉结合。

考虑到用户体验，我选择采用**推模式**，直接将消息发送到每个关注者的收件箱中，降低用户的等待响应时间。

在用户读取消息的时候肯定得采用分页查询的方式，如果依然采用传统的分页方式，就会导致，用户划到第二页的时候可能会出现**重复消息**，因为这时候是有可能收到新的推送的。因此采用**滚动分页**的方式，记录上一次查询的末尾数据的时间戳，并且查询一个**偏移量**，因为可能一个时间戳同时收到多个消息。下一次查询分页数据的时候从这个通过时间戳和偏移量来选择查询的起始位置。



